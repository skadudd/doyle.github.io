<!DOCTYPE html>
<html lang="ko">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="keywords" content="머신러닝">
  
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>모델 평가하는 방법 | Data Archive Doyle</title>
<meta name="generator" content="Jekyll v3.8.7" />
<meta property="og:title" content="모델 평가하는 방법" />
<meta name="author" content="Doyle" />
<meta property="og:locale" content="ko_KR" />
<meta name="description" content="이진분류 정확도 Accuracy (전체 데이터 중 맞게 예측한 것의 비율) $\dfrac{TP + TN}{TP + TN + FP + FN}$ 정밀도 Precision (양성이라 예측한 것 중에서 실제 양성의 비율) $\dfrac{TP}{TP + FP}$ Recall (TPR)(참인 데이터들 중에서 참이라고 예측한것) $\dfrac{TP}{TP+FN}$ Fall Out (FPR False Position Ratio) (실제 양성이 아닌데 양성이라 잘못 에측한 경우) $\dfrac{FP}{FP + TN}$ F1 Score (Recall과 Precision을 결합한 지표) F-score에서 $\beta$ 를 1로 둔다. $F_\beta = (1+\beta)(precision \times recall)$ $\therefore F_1 = (2)(precision \times recall)$ ROC 곡선 FPR이 x축, TPR이 y축으로, FPR이 변할때 TPR의 변화를 그림 FPR : recall, FPR : fall-out 직선에 가까울수록 머신러닝 모델의 성능이 떨어지는것으로 판단한다. 완벽한 분류 시 적당히 잘 분류 시 분류 성능이 나쁠 시 AUC ROC 곡선 아래의 면적이다. 일반적으로 1에 가까울 수록 좋은 수치를 가진다. 기울기가 1인 직선 아래의 면적이 0.5 ⇒ AUC는 0.5보다 커야한다. wine 분류기 ROC 커브" />
<meta property="og:description" content="이진분류 정확도 Accuracy (전체 데이터 중 맞게 예측한 것의 비율) $\dfrac{TP + TN}{TP + TN + FP + FN}$ 정밀도 Precision (양성이라 예측한 것 중에서 실제 양성의 비율) $\dfrac{TP}{TP + FP}$ Recall (TPR)(참인 데이터들 중에서 참이라고 예측한것) $\dfrac{TP}{TP+FN}$ Fall Out (FPR False Position Ratio) (실제 양성이 아닌데 양성이라 잘못 에측한 경우) $\dfrac{FP}{FP + TN}$ F1 Score (Recall과 Precision을 결합한 지표) F-score에서 $\beta$ 를 1로 둔다. $F_\beta = (1+\beta)(precision \times recall)$ $\therefore F_1 = (2)(precision \times recall)$ ROC 곡선 FPR이 x축, TPR이 y축으로, FPR이 변할때 TPR의 변화를 그림 FPR : recall, FPR : fall-out 직선에 가까울수록 머신러닝 모델의 성능이 떨어지는것으로 판단한다. 완벽한 분류 시 적당히 잘 분류 시 분류 성능이 나쁠 시 AUC ROC 곡선 아래의 면적이다. 일반적으로 1에 가까울 수록 좋은 수치를 가진다. 기울기가 1인 직선 아래의 면적이 0.5 ⇒ AUC는 0.5보다 커야한다. wine 분류기 ROC 커브" />
<link rel="canonical" href="http://localhost:4000/articles/2023/02/10/%EB%AA%A8%EB%8D%B8-%ED%8F%89%EA%B0%80-%EB%B3%B5%EC%82%AC%EB%B3%B8-2" />
<meta property="og:url" content="http://localhost:4000/articles/2023/02/10/%EB%AA%A8%EB%8D%B8-%ED%8F%89%EA%B0%80-%EB%B3%B5%EC%82%AC%EB%B3%B8-2" />
<meta property="og:site_name" content="Data Archive Doyle" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-02-10T15:00:00+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="모델 평가하는 방법" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Doyle"},"dateModified":"2023-02-10T15:00:00+09:00","datePublished":"2023-02-10T15:00:00+09:00","description":"이진분류 정확도 Accuracy (전체 데이터 중 맞게 예측한 것의 비율) $\\dfrac{TP + TN}{TP + TN + FP + FN}$ 정밀도 Precision (양성이라 예측한 것 중에서 실제 양성의 비율) $\\dfrac{TP}{TP + FP}$ Recall (TPR)(참인 데이터들 중에서 참이라고 예측한것) $\\dfrac{TP}{TP+FN}$ Fall Out (FPR False Position Ratio) (실제 양성이 아닌데 양성이라 잘못 에측한 경우) $\\dfrac{FP}{FP + TN}$ F1 Score (Recall과 Precision을 결합한 지표) F-score에서 $\\beta$ 를 1로 둔다. $F_\\beta = (1+\\beta)(precision \\times recall)$ $\\therefore F_1 = (2)(precision \\times recall)$ ROC 곡선 FPR이 x축, TPR이 y축으로, FPR이 변할때 TPR의 변화를 그림 FPR : recall, FPR : fall-out 직선에 가까울수록 머신러닝 모델의 성능이 떨어지는것으로 판단한다. 완벽한 분류 시 적당히 잘 분류 시 분류 성능이 나쁠 시 AUC ROC 곡선 아래의 면적이다. 일반적으로 1에 가까울 수록 좋은 수치를 가진다. 기울기가 1인 직선 아래의 면적이 0.5 ⇒ AUC는 0.5보다 커야한다. wine 분류기 ROC 커브","headline":"모델 평가하는 방법","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/articles/2023/02/10/%EB%AA%A8%EB%8D%B8-%ED%8F%89%EA%B0%80-%EB%B3%B5%EC%82%AC%EB%B3%B8-2"},"url":"http://localhost:4000/articles/2023/02/10/%EB%AA%A8%EB%8D%B8-%ED%8F%89%EA%B0%80-%EB%B3%B5%EC%82%AC%EB%B3%B8-2"}</script>
<!-- End Jekyll SEO tag -->

  
  <link rel="stylesheet" href="/css/animate.css">
  <link rel="stylesheet" href="/css/main.css">
  <link href="https://unpkg.com/ionicons@4.5.10-0/dist/css/ionicons.min.css" rel="stylesheet">

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"></script>
  <script>
      document.addEventListener("DOMContentLoaded", function() {
          renderMathInElement(document.body, {
              // ...options...
          });
      });
  </script>
  
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@100;300;400;500;700;900&display=swap" rel="stylesheet">

  <link rel="canonical" href="http://localhost:4000/articles/2023/02/10/%EB%AA%A8%EB%8D%B8-%ED%8F%89%EA%B0%80-%EB%B3%B5%EC%82%AC%EB%B3%B8-2">
  <link rel="alternate" type="application/rss+xml" title="Data Archive | Doyle" href="http://localhost:4000/feed.xml">
  <link rel="shortcut icon" type="image/png" href="/assets/images/favicon.png">

  <script src="https://code.jquery.com/jquery-1.12.0.min.js"></script>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=UA-UA-185737211-1"></script> -->
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-185737211-1');
  </script>
</head>

  
  <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    TeX: {
      equationNumbers: {
        autoNumber: "AMS"
      }
    },
    tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$'] ],
    processEscapes: true,
  }
});
MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
	  alert("Math Processing Error: "+message[1]);
	});
MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
	  alert("Math Processing Error: "+message[1]);
	});
</script>
<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
  
  <body>
    <header class="site-header">

  <div class="wrapper">
    <a class="site-title" style="text-decoration: none" href="/">
<!--       &lt;:]{%&gt; == []{} -->
<!--      &lt;<span style="color: #ff5400;">daegikim</span>.github.io/&gt;-->
        Doyle, DA
        <span style="display: inline-block" class=" animated bounceIn">🚀</span>
    </a>
    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>
      <div class="trigger">
           
          <a class="page-link" href="/about">About</a>
          
          <a class="page-link" href="/">Blog</a>
                                               
      </div>
    </nav>
  </div>
</header>

    <div class="page-content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
    </script>
    <script type="text/javascript" src="http://cdn.mathjax.org/math...">
    </script>

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">모델 평가하는 방법</h1>
    <p class="post-meta">
      <span class="left">
        <time datetime="2023-02-10T15:00:00+09:00" itemprop="datePublished">Feb 10, 2023</time>
       <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">Doyle</span></span>
      </span>
      <span class="right">
        <span class="post-author-image" style="background-image:url(/assets/images/conan.png);"></span>
      </span>
    </p>
  </header>
  <div class="post-content" itemprop="articleBody">
    <h3 id="이진분류">이진분류</h3>

<p><img src="https://i.imgur.com/Br7Hc8g.png" alt="" /></p>

<ul>
  <li>
    <p><img src="https://i.imgur.com/qft6Hs1.png" alt="" /></p>
  </li>
  <li>정확도 Accuracy (전체 데이터 중 맞게 예측한 것의 비율)
    <ul>
      <li>$\dfrac{TP + TN}{TP + TN + FP + FN}$</li>
      <li><img src="https://i.imgur.com/HC7uFwU.png" alt="" /></li>
    </ul>
  </li>
  <li>정밀도 Precision (양성이라 예측한 것 중에서 실제 양성의 비율)
    <ul>
      <li>$\dfrac{TP}{TP + FP}$</li>
      <li><img src="https://i.imgur.com/rceWq5b.png" alt="" /></li>
    </ul>
  </li>
  <li>Recall (TPR)(참인 데이터들 중에서 참이라고 예측한것)
    <ul>
      <li>$\dfrac{TP}{TP+FN}$</li>
      <li><img src="https://i.imgur.com/3N0aELf.png" alt="" /></li>
    </ul>
  </li>
  <li>Fall Out (FPR False Position Ratio) (실제 양성이 아닌데 양성이라 잘못 에측한 경우)
    <ul>
      <li>$\dfrac{FP}{FP + TN}$</li>
      <li><img src="https://i.imgur.com/75lQTC1.png" alt="" /></li>
    </ul>
  </li>
  <li>F1 Score (Recall과 Precision을 결합한 지표)
    <ul>
      <li>F-score에서 $\beta$ 를 1로 둔다.
        <ul>
          <li>$F_\beta = (1+\beta)(precision \times recall)$</li>
          <li>$\therefore F_1 = (2)(precision \times recall)$</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>ROC  곡선
    <ul>
      <li>FPR이 x축, TPR이 y축으로, FPR이 변할때 TPR의 변화를 그림
        <ul>
          <li>FPR : recall, FPR : fall-out</li>
        </ul>
      </li>
      <li>직선에 가까울수록 머신러닝 모델의 성능이 떨어지는것으로 판단한다.
        <ul>
          <li>완벽한 분류 시
            <ul>
              <li><img src="https://i.imgur.com/Yfy1ddz.png" alt="" /></li>
            </ul>
          </li>
          <li>적당히 잘 분류 시
            <ul>
              <li><img src="https://i.imgur.com/O8ypt0S.png" alt="" /></li>
            </ul>
          </li>
          <li>분류 성능이 나쁠 시
            <ul>
              <li><img src="https://i.imgur.com/5t2qMGq.png" alt="" /></li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>AUC
    <ul>
      <li>ROC 곡선 아래의 면적이다.</li>
      <li>일반적으로 1에 가까울 수록 좋은 수치를 가진다.</li>
      <li>기울기가 1인 직선 아래의 면적이 0.5 ⇒ AUC는 0.5보다 커야한다.
        <ul>
          <li><img src="https://i.imgur.com/G959pnW.png" alt="" /></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="wine-분류기-roc-커브">wine 분류기 ROC 커브</h4>

<!--more-->
<pre><code class="language-python">import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

red_url = 'https://raw.githubusercontent.com/PinkWink/ML_tutorial/master/dataset/winequality-red.csv'
white_url = 'https://raw.githubusercontent.com/PinkWink/ML_tutorial/master/dataset/winequality-white.csv'
red_wine = pd.read_csv(red_url,sep=';')
white_wine = pd.read_csv(white_url,sep=';')

wine = pd.concat([red_wine,white_wine])
wine['taste'] = [1. if grade &gt; 5 else 0. for grade in wine.quality]

X = wine.drop(['quality','taste'],axis=1)
y = wine['taste']

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state=13)

wine_tree = DecisionTreeClassifier(max_depth = 2, random_state = 13)
wine_tree.fit(X_train,y_train)
y_pred_tr = wine_tree.predict(X_train)
y_pred_test = wine_tree.predict(X_test)

print('Train Acc : ',accuracy_score(y_train,y_pred_tr))
print('Train Acc : ',accuracy_score(y_test,y_pred_test))

from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve)

print('Acurracy: ', accuracy_score(y_test, y_pred_test))
print('Recall: ', recall_score(y_test, y_pred_test))
print('Precision: ', precision_score(y_test, y_pred_test))
print('AUC score: ', roc_auc_score(y_test, y_pred_test))
print('F1 Score: ', f1_score(y_test, y_pred_test))

import matplotlib.pyplot as plt

pred_proba = wine_tree.predict_proba(X_test)[:,1]
fpr, tpr, thresholds = roc_curve(y_test, pred_proba)

plt.figure(figsize=(10,8))
plt.plot([0,1],[0,1])
plt.plot(fpr,tpr)
plt.grid()
plt.show()
</code></pre>

  </div>
</article>
<!-- 

<div id="disqus_thread"></div>
<script>
  (function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = 'https://daegikim.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
 -->

      </div>
    </div>
    <footer class="site-footer">
  <div class="wrapper">
    <div class="footer-heading">
      copyrignt
      <span style="display: inline-block; vertical-align: middle; transform: rotate(180deg)">&copy;</span>
      all rights reserved
    </div>
    <a href="https://github.com/skadudd"><i class="icon ion-logo-github"></i></a>
    <!-- <a href="https://www.linkedin.com/in/daegi-kim-6b23045b"><i class="icon ion-logo-linkedin"></i></a> -->
    <a href="https://www.instagram.com/naamyoung/"><i class="icon ion-logo-instagram"></i></a>
  </div>
</footer>

  </body>
</html>