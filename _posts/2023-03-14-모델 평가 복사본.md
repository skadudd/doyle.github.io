---
layout: post
title:  "모델 평가하는 방법"
date:   2021-03-13 15:00:00 +0900
comments: true
categories: programming
tags: [모델평가, 머신러닝]
keywords: [머신러닝]
image: /assets/images/posts/common/25673_21329_0.jpg
excerpt_separator: <!--more-->
use_math:true
---

### 이진분류


![](https://i.imgur.com/Br7Hc8g.png)

- 
![](https://i.imgur.com/qft6Hs1.png)

- 정확도 Accuracy (전체 데이터 중 맞게 예측한 것의 비율)
	- $\dfrac{TP + TN}{TP + TN + FP + FN}$
	- ![](https://i.imgur.com/HC7uFwU.png)

- 정밀도 Precision (양성이라 예측한 것 중에서 실제 양성의 비율)
	- $\dfrac{TP}{TP + FP}$
	- ![](https://i.imgur.com/rceWq5b.png)

- Recall (TPR)(참인 데이터들 중에서 참이라고 예측한것)
	- $\dfrac{TP}{TP+FN}$
	- ![](https://i.imgur.com/3N0aELf.png)

- Fall Out (FPR False Position Ratio) (실제 양성이 아닌데 양성이라 잘못 에측한 경우)
	- $\dfrac{FP}{FP + TN}$
	- ![](https://i.imgur.com/75lQTC1.png)
- F1 Score (Recall과 Precision을 결합한 지표)
	- F-score에서 $\beta$ 를 1로 둔다.
		- $F_\beta = (1+\beta)(precision \times recall)$ 
		- $\therefore F_1 = (2)(precision \times recall)$ 
- ROC  곡선
	- FPR이 x축, TPR이 y축으로, FPR이 변할때 TPR의 변화를 그림
		- FPR : recall, FPR : fall-out
	- 직선에 가까울수록 머신러닝 모델의 성능이 떨어지는것으로 판단한다.
		- 완벽한 분류 시
			- ![](https://i.imgur.com/Yfy1ddz.png)
		- 적당히 잘 분류 시
			- ![](https://i.imgur.com/O8ypt0S.png)
		- 분류 성능이 나쁠 시
			- ![](https://i.imgur.com/5t2qMGq.png)
- AUC
	- ROC 곡선 아래의 면적이다.
	- 일반적으로 1에 가까울 수록 좋은 수치를 가진다.
	- 기울기가 1인 직선 아래의 면적이 0.5 ⇒ AUC는 0.5보다 커야한다.
		- ![](https://i.imgur.com/G959pnW.png)

#### wine 분류기 ROC 커브

<!--more-->
```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

red_url = 'https://raw.githubusercontent.com/PinkWink/ML_tutorial/master/dataset/winequality-red.csv'
white_url = 'https://raw.githubusercontent.com/PinkWink/ML_tutorial/master/dataset/winequality-white.csv'
red_wine = pd.read_csv(red_url,sep=';')
white_wine = pd.read_csv(white_url,sep=';')

wine = pd.concat([red_wine,white_wine])
wine['taste'] = [1. if grade > 5 else 0. for grade in wine.quality]

X = wine.drop(['quality','taste'],axis=1)
y = wine['taste']

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state=13)

wine_tree = DecisionTreeClassifier(max_depth = 2, random_state = 13)
wine_tree.fit(X_train,y_train)
y_pred_tr = wine_tree.predict(X_train)
y_pred_test = wine_tree.predict(X_test)

print('Train Acc : ',accuracy_score(y_train,y_pred_tr))
print('Train Acc : ',accuracy_score(y_test,y_pred_test))

from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve)

print('Acurracy: ', accuracy_score(y_test, y_pred_test))
print('Recall: ', recall_score(y_test, y_pred_test))
print('Precision: ', precision_score(y_test, y_pred_test))
print('AUC score: ', roc_auc_score(y_test, y_pred_test))
print('F1 Score: ', f1_score(y_test, y_pred_test))

import matplotlib.pyplot as plt

pred_proba = wine_tree.predict_proba(X_test)[:,1]
fpr, tpr, thresholds = roc_curve(y_test, pred_proba)

plt.figure(figsize=(10,8))
plt.plot([0,1],[0,1])
plt.plot(fpr,tpr)
plt.grid()
plt.show()
```
